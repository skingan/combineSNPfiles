#!/usr/bin/perl -w

####################################################################################################
#
#		Sarah B. Kingan
#		University of Rochester
#		13 January 2014
#
#		Title: combineSNPfiles.pl
#
#
#		This program generates a single SNP file from multiple individual snp files
#			that were generated by popbam snp. The snp files must be compressed with
#			bgzip and indexed with tabix.
#
#				bgzip -c myfile.snp > myfile.snp.bgz
#				tabix -b 2 -e 2 -s 1 myfile.snp.bgz
#	
#		Input: 
#			text file with list of files to be combined, one file per line
#
#		Output: 
#			single snp file printed to STDOUT
#			
#
####################################################################################################

use strict;
use Tabix;
use Bio::Seq;
use Bio::DB::Fasta;
use Data::Dumper;

my $usage = "combineSNPfiles.pl <file_list.txt>\n";


# read list of file names into array
my $file_list = $ARGV[0] or die $usage;
open (LIST, $file_list);
my @file_list;
while (my $line = <LIST>) {
	chomp$line;
	push(@file_list, $line);
}

# make hash for contig - length pairs
#my @contigs = qw(4_group2 XL_group3b);
#my @lengths = (1235759, 388551);
my @contigs = qw(2 3 4_group1 4_group2 4_group3 4_group4 4_group5 XL_group1a XL_group1e XL_group3a XL_group3b XR_group3a XR_group5 XR_group6 XR_group8);
my @lengths = qw(30819483 19787792 5287126 1235759 11685562 6594820 2439919 9148293 12541198 2692213 388551 1469181 740970 13333775 9197557);

# Setup reference fasta database
my $ref_fasta_file = "/home/data/pseudo/dpse_r3.1_reduced.fa";
my $ref_fastaDB = Bio::DB::Fasta->new($ref_fasta_file);

# create and store tabix object in an array
my $tabix_object;
my @tabix_object_array;
foreach my $file (@file_list) {
	$tabix_object = Tabix->new(-data => $file);
	push(@tabix_object_array, $tabix_object);
}
		

## compile all snps ##
# loop through each contig
for (my $i=0; $i<scalar(@contigs); $i++) {

	print STDERR "working on contig: ", $contigs[$i], "\n";

	# get array of unique positions across all samples
	my @positions = get_unique_positions($contigs[$i], $lengths[$i], \@tabix_object_array);

	print STDERR "total of ", scalar@positions, " for ", $contigs[$i], "\n";

	# query each unique snp position
	for (my $p=0; $p<scalar(@positions); $p++) {
	
		print STDERR "obtaining snp data for: ", $contigs[$i], ": ", $positions[$p], "\n";

		# fetch reference base for position
		my $ref_base = $ref_fastaDB->seq($contigs[$i],$positions[$p],$positions[$p]);

		# print contig name, postion, reference base
		print join("\t", ($contigs[$i], $positions[$p], $ref_base));
	
		# query each sample for position
		for (my $t=0; $t<scalar(@tabix_object_array); $t++) {
		
			print STDERR "\tfor sample number: ", $t+1, "\n";
		
			my $interval = $tabix_object_array[$t]->query($contigs[$i], $positions[$p]-1, $positions[$p]);
			my $line = $tabix_object_array[$t]->read($interval);
			my @line_array;
			
			# print snp data if position exists in file
			if ($line) {
				@line_array = split("\t", $line);
				print "\t", join("\t", @line_array[3..6]);
			}
			
			# or print reference base and dummy qualities
			else {
				print "\t", join("\t", ($ref_base, 30,30,5));
			}
		}
		print "\n";
	}
	
}



#### SUBROUTINES ####

sub uniq {
	my @input = @_;
	my %hash;
	foreach my $a (@input) {
		$hash{$a} = '1';
	}
	my @output = (sort { $a <=> $b } keys %hash);
	return @output;
}


sub get_unique_positions {
	my ($contig, $length, $tabix_array_reference) = @_;
	my @tabix_array = @$tabix_array_reference;
	my @positions;
	print STDERR "getting SNP positions...\n";
	for (my $t = 0; $t<scalar(@tabix_array); $t++) {
		my $interval = $tabix_array[$t]->query($contig, 1, $length);
		print STDERR "\tfor sample number: ", $t+1, "\n";
		while (my $line = $tabix_array[$t]->read($interval)) {
			my @line_array = split("\t", $line);
			push(@positions, $line_array[1]);
		}
	}
	my @unique_positions = uniq(@positions);
	return @unique_positions;
}
	
